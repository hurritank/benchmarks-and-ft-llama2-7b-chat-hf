{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXm3PVGiPaCvTjJaYjYwrB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xNlCJN64iQyx"},"outputs":[],"source":["!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n","!pip install scipy\n","!pip install tensorboard\n","!pip install huggingface_hub\n","!huggingface-cli login --token '##############'\n","!pip install json5"]},{"cell_type":"code","source":["from tqdm import tqdm\n","import os\n","import torch\n","from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n","import transformers\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer\n","\n","import json5\n","import string\n","import re\n","import csv"],"metadata":{"id":"MmJd90JViaO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model_tokenizer(model_name, adapter_name, quantization=False):\n","    if quantization:\n","      bnb_config = BitsAndBytesConfig(\n","      load_in_4bit=True,\n","      bnb_4bit_quant_type=\"nf4\",\n","      bnb_4bit_compute_dtype=\"float16\",\n","      bnb_4bit_use_double_quant=False)\n","    else:\n","      bnb_config = None\n","\n","    model = AutoModelForCausalLM.from_pretrained(model_name, config=bnb_config, device_map=\"auto\")\n","    if adapter_name:\n","      model = PeftModel.from_pretrained(model, adapter_name, device_map=\"auto\")\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.padding_side = \"right\"\n","\n","    return model, tokenizer\n","\n","\n","def predict_response(text):\n","  inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n","  outputs = model.generate(**inputs, max_new_tokens=100)\n","  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","  return response\n","\n","\n","def normalize_answer(text):\n","    if text:\n","        punc = string.punctuation\n","        text = text.lower()\n","        return ''.join(char for char in text if char not in punc)\n","    else:\n","        return None\n"],"metadata":{"id":"Wwu1f0zWiaMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Base model\n","model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n","model, tokenizer = load_model_tokenizer(\n","    model_name=model_name,\n","    adapter_name=None,\n","    quantization=True,\n",")\n","device = torch.device('cuda:0')\n","model.to(device)"],"metadata":{"id":"O31hfI_GjdzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create validation dataset\n","dataset_name = \"squad_v2\"\n","dataset = load_dataset(dataset_name, split=\"validation\")\n","dataset = dataset.shuffle(seed=1279)\n","dataset = dataset.select(range(200))\n","dataset.save_to_disk('data/squad_v2/validation')"],"metadata":{"id":"q_ZA8QLXiaJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Benchmark with only context\n","save_path = 'benchmark_context.csv'\n","with open(save_path, \"w\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Context\", \"Question\", \"Answer\", \"Prediction\", \"Full prediction\"])\n","    for i in tqdm(range(len(dataset['context']))):\n","        context = dataset[i]['context']\n","        question = dataset[i]['question']\n","        if len(dataset[i]['answers']['text']) == 0:\n","            answer = 'impossible to answer'\n","        else:\n","            answer = normalize_answer(dataset[i]['answers']['text'][0])\n","        prompt = f\"\"\"\\\n","<s>{context}\n","{question}\n","ANSWER:\n","``` </s>\"\"\"\n","        full_prediction = predict_response(prompt)\n","        answer_start_index = full_prediction.find(\"ANSWER:\")\n","        prediction = full_prediction[answer_start_index+7:]\n","        prediction = normalize_answer(prediction)\n","        writer.writerow(\n","            [\n","                context,\n","                question,\n","                answer,\n","                prediction,\n","                full_prediction\n","            ]\n","            )\n","        file.flush()\n","\n"],"metadata":{"id":"f0PZ0UY9iaHj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pL-rgvD-iaFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JN-UkMTgiaCh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A-_FworhiZ6k"},"execution_count":null,"outputs":[]}]}